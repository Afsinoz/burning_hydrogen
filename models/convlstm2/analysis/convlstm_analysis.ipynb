{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "caa8f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa43f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "671c55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from convlstm_classes import EncoderDecoderConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "effaaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('../../convlstm/splits/dataset_normalized.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "381cbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3cb22d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[:,11:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8c22a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_full = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7eae82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test = int(0.2 * len_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f91a6aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "668344cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X[-len_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3e365474",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "199d8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_indices = np.random.choice(range(len_test), size=40, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "22b02d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_test[test_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "053d6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_sample.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5f4e5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderConvLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0db854a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../best_model_params.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "94a3ab73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoderConvLSTM(\n",
       "  (encoder_1_convlstm): ConvLSTMCell(\n",
       "    (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (encoder_2_convlstm): ConvLSTMCell(\n",
       "    (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (batchnorm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (decoder_1_convlstm): ConvLSTMCell(\n",
       "    (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder_2_convlstm): ConvLSTMCell(\n",
       "    (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (batchnorm2): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (decoder_CNN): Conv3d(24, 1, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bb5247df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    with torch.no_grad():\n",
    "        return np.array(model(torch.tensor(x)).squeeze(2)[:,1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9f2d0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(model=predict, data=X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5bc7caf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionError",
     "evalue": "Instance must have 1 or 2 dimensions!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDimensionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearn/lib/python3.10/site-packages/shap/explainers/_kernel.py:294\u001b[0m, in \u001b[0;36mKernelExplainer.shap_values\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     emsg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance must have 1 or 2 dimensions!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DimensionError(emsg)\n",
      "\u001b[0;31mDimensionError\u001b[0m: Instance must have 1 or 2 dimensions!"
     ]
    }
   ],
   "source": [
    "shap_values = explainer.shap_values(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa417ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
